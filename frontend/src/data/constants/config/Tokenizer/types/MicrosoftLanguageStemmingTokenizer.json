{
  "discriminatorValue": "#Microsoft.Azure.Search.MicrosoftLanguageStemmingTokenizer",
  "label": "MicrosoftLanguageStemmingTokenizer",
  "description": "Divides text using language-specific rules and reduces words to their base forms.",
  "fields": [
    {
      "key": "isSearchTokenizer",
      "label": "Is Search Tokenizer",
      "type": "boolean",
      "default": false,
      "tooltip": "A value indicating how the tokenizer is used. Set to true if used as the search tokenizer, set to false if used as the indexing tokenizer. Default is false."
    },
    {
      "key": "language",
      "label": "Language",
      "type": "string",
      "placeholder": "english",
      "tooltip": "The language to use. The default is English."
    },
    {
      "key": "maxTokenLength",
      "label": "Max Token Length",
      "type": "number",
      "default": 255,
      "min": 1,
      "max": 300,
      "tooltip": "The maximum token length. Tokens longer than the maximum length are split. Maximum token length that can be used is 300 characters. Tokens longer than 300 characters are first split into tokens of length 300 and then each of those tokens is split based on the max token length set. Default is 255."
    }
  ]
}
