{
  "discriminatorValue": "#Microsoft.Azure.Search.KeywordTokenizerV2",
  "label": "KeywordTokenizerV2",
  "description": "Emits the entire input as a single token. Implemented using Apache Lucene.",
  "fields": [
    {
      "key": "maxTokenLength",
      "label": "Max Token Length",
      "type": "number",
      "default": 256,
      "min": 1,
      "max": 300,
      "tooltip": "The maximum token length. Default is 256. Tokens longer than the maximum length are split. The maximum token length that can be used is 300 characters."
    }
  ]
}
